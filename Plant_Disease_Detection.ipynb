{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAzpDpsMNsrX"
      },
      "outputs": [],
      "source": [
        "# Step 1: Data Acquisition\n",
        "# Download the Plant disease dataset from Kaggle\n",
        "\n",
        "# Install kaggle\n",
        "!pip install kaggle\n",
        "\n",
        "# Mount the Google drive so that you can store your Kaggle API credentials\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a Kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Copy the kaggle.json file to the Kaggle directory\n",
        "!cp /content/drive/MyDrive/Kaggle/kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set permissions for the Kaggle API key\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset using the Kaggle API\n",
        "!kaggle datasets download -d emmarex/plantdisease\n",
        "\n",
        "# Unzip the dataset (if needed)\n",
        "!unzip plantdisease.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0vqBQi6Ogwr"
      },
      "outputs": [],
      "source": [
        "# Step 2: Loading and augment the dataset(Augmentation: Techniques applied to increase dataset diversity, helping the model generalize better)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load dataset\n",
        "data_dir = 'PlantVillage/'\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Data preprocessing for validation set (no augmentation)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create validation data generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXjDcUh1PPux"
      },
      "outputs": [],
      "source": [
        "# Step 3: Use Transfer learning with a pre-trained model\n",
        "# Model Selection\n",
        "# Utilize ResNet50, a well-established convolutional neural network known for its effectiveness in image classification tasks, particularly in plant disease detection\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50  # ResNet50 is a popular deep learning model that is 50 layers deep\n",
        "from tensorflow.keras.models import Model # Class used to define a 'Keras' model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Define a base model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Adding a custom layer\n",
        "x = base_model.output # Take the output of the base_model ResNet50\n",
        "x = GlobalAveragePooling2D()(x) # This layer applies global average pooling to the feature map\n",
        "\n",
        "# Adding fully connected layers\n",
        "x = Dense(256, activation='relu')(x)  # Dense layer for helping the model learn complex patterns\n",
        "predictions = Dense(15, activation='softmax')(x)  # Another fully connected layer with 38 neurons(classes). The softmax activation function converts the output into praobabilities for each class so that they sum to 1, suitable for multi classification problems\n",
        "\n",
        "# Creating the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions) # inputs: base_model input layer and output:'predictions', which contain the probabilities of each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q2bHnKE9ae_j"
      },
      "outputs": [],
      "source": [
        "# Step 4: Compiling the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7Umu2pdatr8"
      },
      "outputs": [],
      "source": [
        "# Step 5: Training the model using augmented data while validating it against a seperate validation test\n",
        "model.fit(train_generator, epochs=10, validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2cRhtyya8QD"
      },
      "outputs": [],
      "source": [
        "# Step 6: Fine-tuning the model, by unfreezing some of the deeper layers of ResNet50\n",
        "for layer in base_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_generator, epochs=10, validation_data=validation_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YypJtSjvbGKd"
      },
      "outputs": [],
      "source": [
        "# Step 7: Upload the image and predict the class of the image with the model\n",
        "from google.colab import files\n",
        "# Import the Image module instead of the Image class\n",
        "from PIL import Image as PILImage\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Upload image\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename of the uploaded image\n",
        "img_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Open and preprocess the image\n",
        "# Use PILImage.open instead of Image.open\n",
        "img = PILImage.open(img_name)\n",
        "img = img.resize((224, 224))  # Resize to match model input size\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Display the image\n",
        "display(Image(filename=img_name))\n",
        "\n",
        "# Perform prediction\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "# Map predicted class index to class name\n",
        "class_names = {v: k for k, v in train_generator.class_indices.items()}\n",
        "predicted_class_name = class_names[predicted_class]\n",
        "print(f\"Predicted class: {predicted_class_name}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}